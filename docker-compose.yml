version: '3.8'

services:
  florence-service:
    build: .
    container_name: florence_ai
    image: florence_ai
    # This automatically loads your .env file
    env_file: .env
    ports:
      - "${CHAINLIT_PORT}:${CHAINLIT_PORT}"
    volumes:
      - .:/app
      - florence_model_cache:/app/model_cache
    restart: unless-stopped
    # Use the port from .env directly in the start command
    command: chainlit run chainlit_app.py --host 0.0.0.0 --port ${CHAINLIT_PORT}

volumes:
  florence_model_cache: